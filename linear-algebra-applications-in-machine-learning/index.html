<!doctype html>
<html lang="EN">
<head>
  <script id="usercentrics-cmp" src="https://app.usercentrics.eu/browser-ui/latest/loader.js" data-settings-id="DH1Rs7wCZAKJtQ" async></script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta charset='UTF-8'>
  <meta name='keywords' content='python, machine learning'>
  <meta name='description' content='Educating programmers about interesting, 
    crucial topics. Articles are intended to break down tough subjects, while 
    being friendly to beginners'>
  <meta name='subject' content='Python / Machine Learning articles'>
  <meta name='copyright' content='pythonkitchen.com'>
  <meta name='language' content='EN'>
  <meta name='robots' content='index,follow'>
  <meta name='revised' content='Wednesday, August 30thth, 2023, 13:30 pm'>
  <meta name='abstract' content=''>
  <meta name='topic' content='python'>
  <meta name='summary' content=''>
  <meta name='Classification' content='Education'>
  <meta name='author' content='PythonKitchen, email@hotmail.com'>
  <meta name='designer' content=''>
  <meta name='reply-to' content='email@hotmail.com'>
  <meta name='owner' content=''>
  <meta name='url' content='https://www.pythonkitchen.com'>
  <meta name='identifier-URL' content='https://www.pythonkitchen.com'>
  <meta name='directory' content='submission'>
  
  
  <meta name='target' content='all'>
  <meta name='HandheldFriendly' content='True'>
  <meta name='MobileOptimized' content='320'>
  <meta name='date' content='2025-02-15 15:40:00'>
  <meta name='DC.title' content='Quality Python articles'>
  <meta name='ResourceLoaderDynamicStyles' content=''>
  <meta name='medium' content='blog'>
  <!-- <meta name='verify-v1' content='dV1r/ZJJdDEI++fKJ6iDEl6o+TMNtSu0kv18ONeqM0I='>
  <meta name='y_key' content='1e39c508e0d87750'> -->
  
  <meta http-equiv='Expires' content='0'>
  <meta http-equiv='Pragma' content='no-cache'>
  <meta http-equiv='Cache-Control' content='no-cache'>
  <meta http-equiv='imagetoolbar' content='no'>
  <meta http-equiv='x-dns-prefetch-control' content='off'>

  
  <meta name='og:type' content='blog'>
  <meta name='og:site_name' content='PythonKitchen'>
  <meta name='og:description' content='Educating programmers about interesting, 
  crucial topics. Articles are intended to break down tough subjects, while 
  being friendly to beginners'>

  <link rel="shortcut icon" href="/assets/logo.png" /> 
  
  <script src="https://cdn.tailwindcss.com"></script>
  <style>

  </style>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4895581427484601" crossorigin="anonymous"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-161612035-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-161612035-3');
</script>

<script type="text/javascript">
  (function(c,l,a,r,i,t,y){
      c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
      t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
      y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
  })(window, document, "clarity", "script", "ejj5ivpuup");
</script>

  <meta name='Linear Algebra Applications in Machine Learning' content=''>
  <meta name='category' content='data science'>
  <meta name='coverage' content='Worldwide'>
  <meta name='distribution' content='Global'>
  <meta name='rating' content='General'>
  <meta name='revisit-after' content='1 year'>
  <meta name='subtitle' content='Linear Algebra Applications in Machine Learning'>
  <meta name='pageKey' content='linear-algebra-applications-in-machine-learning'>
  <meta name='og:title' content='Linear Algebra Applications in Machine Learning'>
  <meta name='og:url' content='https://www.pythonkitchen.com/linear-algebra-applications-in-machine-learning'>

  <title>Linear Algebra Applications in Machine Learning</title>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/default.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/python.min.js"></script>

<link rel="stylesheet" href="/css/post.css"> 
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.4/css/lightbox.min.css" integrity="sha512-ZKX+BvQihRJPA8CROKBhDNvoc2aDMOdAlcm7TUQY+35XYtrd3yh95QOOhsPDQY9QnKE0Wqag9y38OIgEvb88cA==" crossorigin="anonymous" referrerpolicy="no-referrer" />


</head>
<body class="bg-gray-50">

<nav class="bg-white border-gray-200 dark:bg-gray-900">
    <div class="max-w-screen-xl flex flex-wrap items-center justify-between mx-auto p-4">
      <a href="/" class="flex items-center">
          <img src="/assets/logo.png" class="h-8 mr-3" alt="PythonKitchen Logo" 
            style="width: 50px !important; height: 50px !important;"/>
          <span class="self-center text-2xl font-semibold whitespace-nowrap dark:text-white">PythonKitchen</span>
      </a>
      <button data-collapse-toggle="navbar-default" type="button" class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm text-gray-500 rounded-lg md:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200 dark:text-gray-400 dark:hover:bg-gray-700 dark:focus:ring-gray-600" aria-controls="navbar-default" aria-expanded="false">
          <span class="sr-only">Open main menu</span>
          <svg class="w-5 h-5" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 17 14">
              <path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M1 1h15M1 7h15M1 13h15"/>
          </svg>
      </button>
      <div class="hidden w-full md:block md:w-auto" id="navbar-default">
        <ul class="font-medium flex flex-col p-4 md:p-0 mt-4 border border-gray-100 rounded-lg bg-gray-50 md:flex-row md:space-x-8 md:mt-0 md:border-0 md:bg-white dark:bg-gray-800 md:dark:bg-gray-900 dark:border-gray-700">
          <li>
            <a href="/" 
            class="block py-2 pl-3 pr-4 text-white bg-blue-700 rounded md:bg-transparent md:text-blue-700 md:p-0 dark:text-white md:dark:text-blue-500" aria-current="page">
            Home</a>
          </li>
          <li>
            <a href="https://docs.google.com/forms/d/e/1FAIpQLSdnP_IW4nK95hv-eBDIlxHb5E5DeOniFWBi9YmxlHZARLJDAQ/viewform" class="block py-2 pl-3 pr-4 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent">
              Write</a>
          </li>
          <li>
            <a href="https://forms.gle/gf1p1Aitw9M9m8Zy5" class="block py-2 pl-3 pr-4 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent">
              Contact</a>
          </li>
          <!-- <li>
            <a href="#" class="block py-2 pl-3 pr-4 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent">Pricing</a>
          </li>
          <li>
            <a href="#" class="block py-2 pl-3 pr-4 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent">Contact</a>
          </li> -->
        </ul>
      </div>
    </div>
  </nav>
  
  

<div class="p-8">

</div>

<div class="grid grid-cols-4">
    <div class="col-span-3">
        <div class="p-8 pl-12">
            <div class="ml-2">
                <div class=" bg-white rounded-lg shadow-lg" style="padding: 4vw !important;">
                    <p class="text-3xl" style="font-weight: 600;">Linear Algebra Applications in Machine Learning</p>
                    <br>
                    <div class="flex items-center gap-x-4 text-xs">
                        <time datetime="2023-02-27 10:10:51" class="text-gray-500">February 27, 2023</time>
                        
                        <a href="#" class="relative z-10 rounded-full bg-gray-50 px-3 py-1.5 font-medium text-gray-600 hover:bg-gray-100">
                            data science
                        </a>
                        
                        <a href="#" class="relative z-10 rounded-full bg-gray-50 px-3 py-1.5 font-medium text-gray-600 hover:bg-gray-100">
                            machine learning
                        </a>
                        
                    </div>
                    
                        <div class="relative mt-8 flex items-center gap-x-4">
                            <img src="https://github.com/ParthShukla211.png?size=40" alt="" class="h-10 w-10 rounded-full bg-gray-50">
                            <div class="text-sm leading-6">
                            <p class="font-semibold text-gray-900">
                                <a href='https://www.linkedin.com/in/parthshukla211/'>
                                <span class="absolute inset-0"></span>
                                Parth Shukla
                                </a>
                            </p>
                            <p class="text-gray-600">Ml wizard</p>
                            </div>
                        </div>
                    
                    <br>
                    <article>
                        <p>We can take linear algebra as a backbone of machine learning, as almost all the machine learning techniques and algorithms somehow use linear algebra to some extent. Some famous machine learning techniques like Principle component analysis and matrix factorization are entirely based on linear algebra. Although not only in dimensionality reduction, it is also helpful for some NLP and machine learning algorithms and preprocessing of data applications.</p>
<p>This article will discuss the linear algebra application in machine learning from the perspective of NLP, computer vision, and dimensionality reduction techniques. This article will help one to understand the importance of linear algebra in machine learning and help one understand how linear algebra helps in these techniques.</p>
<h1>Table of Contents</h1>
<ol>
<li>Loss functions</li>
<li>Covariance and Correlations</li>
<li>Support Vector Machines (SVM)</li>
<li>Principle Component Analysis (PCA)</li>
<li>Word Embeddings</li>
<li>Key Takeaways</li>
<li>Conclusion</li>
</ol>
<h1>1. Loss Functions</h1>
<p>We know that loss functions are used for calculating the error that model is making while predicting. Our main aim is to reduce the model&rsquo;s error by understanding where the model makes mistakes and how much bigger it is. In the normal loss function, we directly calculate the distance between the actual data point and the predicted data point by the model, and based on the distance between those two data points, we calculate the error of the model.</p>
<p>The distance between these two data points is either calculated by the euclidian distance or the manhattan distance and in both of the calculations, linear algebra plays a significant role. Here the manhattan distance is the distance if you travel to the point from the axis itself, whereas the euclidian distance is the distance that is obtained by drawing a vector to the data point.</p>
<h1>2. Correlations and Covariance</h1>
<p>Covariance and correlations are powerful data exploration techniques used to study the behavior of the data features and their relationships. The covariance measures how the value of one part changes if we change the value of another variable. Here the covariance between two variables is positive, which means the change in one variable would positively affect the change in another variable in the same direction as the other variable and vice versa.</p>
<p>Correlation is also exact, like the covariance matrix, which can be represented between the value -1 to 1. Here 1 indicated the strong positive correlation between the two variables, and -1 indicated the strong negative correlation between the two variables.</p>
<p>Here, linear algebra plays a significant role while calculating the correlations and covariance between the different features of the dataset. Here the covariance is computed using the matric form of the dataset and the transpose of the same.</p>
<p>The formula to calculate the covariance of covariance is</p>
<blockquote>
<p>Covariance = Xt*X</p>
<p>X = Standard Matrix</p>
<p>Xt = Transpose of the Matrix X</p>
</blockquote>
<p>The covariance and correlations obtained from using liner algebra helps understand the dependence of the feature on other features and allow the selection of the best features that represent the data well and hence are used for features selection.</p>
<h1>3. Support vector Machines (SVM)</h1>
<p>Support vector machine is a famous machine learning algorithm for classification and regression problems. It has a considerable application of linear algebra in its working mechanism. Here basically, in a vector space, support vectors are drawn. If we have two classes to classify, then we will have two vectors or support vectors that will be drawn in the dimensional space. Then the classes or data observations will be classified based on where they lie before or after the support vectors.</p>
<p>So here, linear algebra plays a significant role;e while deciding the support vectors and the decision boundaries for different classes. In the case of nonlinear data that is not separable from the linear line, the kernel trick is used where the polynomial features are used.</p>
<h1>4. Principle Component Analysis (PCA)</h1>
<p>Principle component analysis is the famous technique used for dimensionality reduction of the dataset where we have many features. There is a need to reduce the number of features for lower computation complexity and faster results. It is one of the famous applications of linear algebra.</p>
<p>Here to reduce the dimensionality of the dataset, first, the dataset is normalized. Then the covariance matrix is obtained for the dataset by calculating the eigenvector and eigenvalues. After that, the principle component is drawn in the dimensions, representing all the dataset&rsquo;s features in fewer features. Here the number of principal components decided the new dimensionality of the dataset.</p>
<p>Linear algebra plays a significant role while calculating the covariance matrix, eigenvalues, eigenvectors, and the principle components for the dataset.</p>
<h1>5. Word Embeddings</h1>
<p>Word embeddings are used in natural language processing where the words are represented as a lower dimensional vector without losing their essence or importance. Word2Vec is one of the most used techniques used for word embeddings.</p>
<p>Here different words are represented as a vector in the dimensions, and the words having the same meaning will also lie very close in the measurements. For example, words like Small Boy and Kid are almost similar, and hence they will lie together somewhere in the vector spaces. Linear algebra will help transform the words into vector forms with keeping their importance and meaning.</p>
<h1>Key Takeaways</h1>
<ol>
<li>Linear algebra is the backbone of machine learning as it is essential for almost all machine learning techniques and algorithms.</li>
<li>Linear algebra helps in loss function where the model error is calculated by the distance between actual and predicted data observation in the dimensions.</li>
<li>In data preprocessing techniques like covariance and correlations, Linear algebra helps calculate them with the help of matric multiplications and the transpose of the same.</li>
<li>In the famous machine learning algorithm Support Vector machine, linear algebra helps define the support vectors and the decision boundaries to classify different data observations.</li>
<li>Diomentionallity reduction techniques like PCA are a huge application of linear algebra and almost wholly rely on linear algebra only.</li>
<li>Algorithms like Word2Vec also use linear algebra, where the words are converted into their vector forms.</li>
</ol>
<h1>Conclusion</h1>
<p>In this article, we discussed the applications of linear algebra in different machine learning fields, like data preprocessing and algorithms. Dimensionality reduction and natural language processing. This article will help one understand the application of linear algebra and help answer the questions related to the same.</p>

                        <script src="https://utteranc.es/client.js"
        repo="pythonkitchen/blog-comments"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
                    </article>
                
                  </div>
                
            </div>
        </div>
        
    </div>
    <div class="col-span-1">
        <div class="p-8 pl-12">
            <div class="ml-2">
                <div class=" bg-white rounded-lg shadow-lg" style="padding: 5px">
                    <article>
                        <a  target="_blank" href="https://leanpub.com/c/flask-masterclass">
                            <img id="side-img" src="/assets/flaskcoursefree.png" style="width: 100% !important">
                        </a>
                        Free Flask Course
                    </article>
                    </div>
                    
                    
            </div>
        </div>

        
    </div>
  </div>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script>hljs.highlightAll();</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.4/js/lightbox.min.js" integrity="sha512-Ixzuzfxv1EqafeQlTCufWfaC6ful6WFqIz4G+dWvK0beHw0NVJwvCKSgafpy5gwNqKmgUfIBraVwkKI+Cz0SEQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script type="text/javascript">
    var img = jQuery("img");

img.each(function() {
   var element = jQuery(this);
   var a = jQuery("<a />", {href: element.attr("src"), "data-lightbox": "test"});

   element.wrap(a);
});

    $("#side-img").parent().removeAttr( "data-lightbox" ).attr("href","https://leanpub.com/c/flask-masterclass").attr("target","_blank");
</script>

</body>
</html>