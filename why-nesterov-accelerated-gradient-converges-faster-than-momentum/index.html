<!doctype html>
<html lang="EN">
<head>
  <script id="usercentrics-cmp" src="https://app.usercentrics.eu/browser-ui/latest/loader.js" data-settings-id="DH1Rs7wCZAKJtQ" async></script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta charset='UTF-8'>
  <meta name='keywords' content='python, machine learning'>

  <meta name='subject' content='Python / Machine Learning articles'>
  <meta name='copyright' content='pythonkitchen.com'>
  <meta name='language' content='EN'>
  <meta name='robots' content='index,follow'>
  <meta name='revised' content='Wednesday, August 30thth, 2023, 13:30 pm'>
  <meta name='abstract' content=''>
  <meta name='topic' content='python'>
  <meta name='summary' content=''>
  <meta name='Classification' content='Education'>
  <meta name='author' content='PythonKitchen, email@hotmail.com'>
  <meta name='designer' content=''>
  <meta name='reply-to' content='email@hotmail.com'>
  <meta name='owner' content=''>
  <meta name='url' content='https://www.pythonkitchen.com'>
  <meta name='identifier-URL' content='https://www.pythonkitchen.com'>
  <meta name='directory' content='submission'>
  
  
  <meta name='target' content='all'>
  <meta name='HandheldFriendly' content='True'>
  <meta name='MobileOptimized' content='320'>
  <meta name='date' content='2026-02-24 18:00:00'>
  <meta name='DC.title' content='Quality Python articles'>
  <meta name='ResourceLoaderDynamicStyles' content=''>
  <meta name='medium' content='blog'>
  <!-- <meta name='verify-v1' content='dV1r/ZJJdDEI++fKJ6iDEl6o+TMNtSu0kv18ONeqM0I='>
  <meta name='y_key' content='1e39c508e0d87750'> -->
  
  <meta http-equiv='Expires' content='0'>
  <meta http-equiv='Pragma' content='no-cache'>
  <meta http-equiv='Cache-Control' content='no-cache'>
  <meta http-equiv='imagetoolbar' content='no'>
  <meta http-equiv='x-dns-prefetch-control' content='off'>

  
  <meta name='og:type' content='blog'>
  <meta name='og:site_name' content='PythonKitchen'>

  <link rel="shortcut icon" href="/assets/logo.png" /> 
  
  <script src="https://cdn.tailwindcss.com"></script>
  <style>

  </style>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4895581427484601" crossorigin="anonymous"></script>
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-161612035-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-161612035-3');
</script>

<script type="text/javascript">
  (function(c,l,a,r,i,t,y){
      c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
      t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
      y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
  })(window, document, "clarity", "script", "ejj5ivpuup");
</script>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Why Nesterov Accelerated Gradient Converges Faster Than Momentum | Python Kitchen</title>
  <meta name="description" content="Gradient-based optimization lies at the heart of modern machine learning. From linear regression to deep neural networks, the efficiency of training depends hea...">
  <meta name="keywords" content="optimization, mathematics, nag, deep learning">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://www.pythonkitchen.com/why-nesterov-accelerated-gradient-converges-faster-than-momentum/">
  <meta property="og:title" content="Why Nesterov Accelerated Gradient Converges Faster Than Momentum">
  <meta property="og:description" content="Gradient-based optimization lies at the heart of modern machine learning. From linear regression to deep neural networks, the efficiency of training depends hea...">
  <meta property="og:image" content="https://www.pythonkitchen.com/assets/banner.png">

  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image">
  <meta property="twitter:url" content="https://www.pythonkitchen.com/why-nesterov-accelerated-gradient-converges-faster-than-momentum/">
  <meta property="twitter:title" content="Why Nesterov Accelerated Gradient Converges Faster Than Momentum">
  <meta property="twitter:description" content="Gradient-based optimization lies at the heart of modern machine learning. From linear regression to deep neural networks, the efficiency of training depends hea...">
  <meta property="twitter:image" content="https://www.pythonkitchen.com/assets/banner.png">

  <meta name='category' content='deep learning'>
  <meta name='coverage' content='Worldwide'>
  <meta name='distribution' content='Global'>
  <meta name='rating' content='General'>
  <meta name='subtitle' content='Why Nesterov Accelerated Gradient Converges Faster Than Momentum'>
  <meta name='pageKey' content='why-nesterov-accelerated-gradient-converges-faster-than-momentum'>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/default.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/python.min.js"></script>

<link rel="stylesheet" href="/css/post.css"> 
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.4/css/lightbox.min.css" integrity="sha512-ZKX+BvQihRJPA8CROKBhDNvoc2aDMOdAlcm7TUQY+35XYtrd3yh95QOOhsPDQY9QnKE0Wqag9y38OIgEvb88cA==" crossorigin="anonymous" referrerpolicy="no-referrer" />

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFas9aVVUsq" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


</head>
<body class="bg-gray-50">

<nav class="bg-white border-gray-200 dark:bg-gray-900">
    <div class="max-w-screen-xl flex flex-wrap items-center justify-between mx-auto p-4">
      <a href="/" class="flex items-center">
          <img src="/assets/logo.png" class="h-8 mr-3" alt="PythonKitchen Logo" 
            style="width: 50px !important; height: 50px !important;"/>
          <span class="self-center text-2xl font-semibold whitespace-nowrap dark:text-white">PythonKitchen</span>
      </a>
      <button data-collapse-toggle="navbar-default" type="button" class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm text-gray-500 rounded-lg md:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200 dark:text-gray-400 dark:hover:bg-gray-700 dark:focus:ring-gray-600" aria-controls="navbar-default" aria-expanded="false">
          <span class="sr-only">Open main menu</span>
          <svg class="w-5 h-5" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 17 14">
              <path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M1 1h15M1 7h15M1 13h15"/>
          </svg>
      </button>
      <div class="hidden w-full md:block md:w-auto" id="navbar-default">
        <ul class="font-medium flex flex-col p-4 md:p-0 mt-4 border border-gray-100 rounded-lg bg-gray-50 md:flex-row md:space-x-8 md:mt-0 md:border-0 md:bg-white dark:bg-gray-800 md:dark:bg-gray-900 dark:border-gray-700">
          <li>
            <a href="/" 
            class="block py-2 pl-3 pr-4 text-white bg-blue-700 rounded md:bg-transparent md:text-blue-700 md:p-0 dark:text-white md:dark:text-blue-500" aria-current="page">
            Home</a>
          </li>
          <li>
            <a href="https://docs.google.com/forms/d/e/1FAIpQLSdnP_IW4nK95hv-eBDIlxHb5E5DeOniFWBi9YmxlHZARLJDAQ/viewform" class="block py-2 pl-3 pr-4 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent">
              Write</a>
          </li>
          <li>
            <a href="https://forms.gle/gf1p1Aitw9M9m8Zy5" class="block py-2 pl-3 pr-4 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent">
              Contact</a>
          </li>
          <!-- <li>
            <a href="#" class="block py-2 pl-3 pr-4 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent">Pricing</a>
          </li>
          <li>
            <a href="#" class="block py-2 pl-3 pr-4 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent">Contact</a>
          </li> -->
        </ul>
      </div>
    </div>
  </nav>
  
  

<div class="p-8">

</div>

<div class="grid grid-cols-4">
    <div class="col-span-3">
        <div class="p-8 pl-12">
            <div class="ml-2">
                <div class=" bg-white rounded-lg shadow-lg" style="padding: 4vw !important;">
                    <p class="text-3xl" style="font-weight: 600;">Why Nesterov Accelerated Gradient Converges Faster Than Momentum</p>
                    <br>
                    <div class="flex items-center gap-x-4 text-xs">
                        <time datetime="2026-02-03 07:00:00" class="text-gray-500">February 3, 2026</time>
                        
                        <a href="#" class="relative z-10 rounded-full bg-gray-50 px-3 py-1.5 font-medium text-gray-600 hover:bg-gray-100">
                            deep learning
                        </a>
                        
                    </div>
                    
                        <div class="relative mt-8 flex items-center gap-x-4">
                            <img src="https://github.com/Abdur-rahmaanJ.png?size=40" alt="" class="h-10 w-10 rounded-full bg-gray-50">
                            <div class="text-sm leading-6">
                            <p class="font-semibold text-gray-900">
                                <a href='https://www.linkedin.com/in/appinv/'>
                                <span class="absolute inset-0"></span>
                                Abdur-Rahmaan Janhangeer
                                </a>
                            </p>
                            <p class="text-gray-600">Chef</p>
                            </div>
                        </div>
                    
                    <br>
                    <article>
                        <p>Gradient-based optimization lies at the heart of modern machine learning. From linear regression to deep neural networks, the efficiency of training depends heavily on how quickly and stably an optimizer can minimize a loss function. While vanilla gradient descent is conceptually simple, it is often too slow and unstable for practical use. This is why momentum-based methods were introduced.</p>
<p>Momentum improves convergence by accumulating past gradients, but it still suffers from overshooting and oscillations, especially in ravines and ill-conditioned landscapes. Nesterov Accelerated Gradient (NAG) refines this idea by adding a simple yet powerful lookahead mechanism. In practice and theory, this small modification leads to faster and more stable convergence.</p>
<p>This article explains <em>why</em> Nesterov Accelerated Gradient converges faster than classical momentum, focusing on intuition, geometry, and optimization dynamics rather than surface-level equations.</p>
<h1>Table of Content</h1>
<ol>
<li>Gradient Descent and the Need for Momentum  </li>
<li>Classical Momentum: Strengths and Limitations  </li>
<li>Nesterov Accelerated Gradient: The Key Idea  </li>
<li>Lookahead Gradients and Error Correction  </li>
<li>Geometric Intuition Behind Faster Convergence  </li>
<li>NAG vs Momentum: Side-by-Side Comparison  </li>
<li>When NAG Helps the Most  </li>
<li>Common Misconceptions  </li>
<li>Key Takeaways  </li>
<li>Conclusion</li>
</ol>
<h1>Gradient Descent and the Need for Momentum</h1>
<p>In standard gradient descent, parameters are updated by moving in the direction of the negative gradient. While this guarantees progress for convex problems under suitable conditions, it is often inefficient in practice.</p>
<p>Loss landscapes frequently contain:</p>
<ul>
<li>Long, narrow valleys</li>
<li>High curvature in one direction and low curvature in another</li>
<li>Noisy gradients in stochastic settings</li>
</ul>
<p>In such cases, vanilla gradient descent oscillates heavily and makes slow progress along the shallow directions. Momentum was introduced to address exactly this issue by smoothing updates over time.</p>
<h1>Classical Momentum: Strengths and Limitations</h1>
<p>Momentum introduces a velocity term that accumulates past gradients. Instead of moving purely based on the current gradient, updates are influenced by a running average of previous gradients.</p>
<p>This has two major benefits:</p>
<ol>
<li>Faster movement along consistent directions</li>
<li>Reduced oscillations in steep directions</li>
</ol>
<p>However, classical momentum has a critical weakness:<br/>
it evaluates the gradient <strong>at the current position</strong>, even though the update will move the parameters forward due to momentum.</p>
<p>As a result:</p>
<ul>
<li>The optimizer often overshoots the minimum</li>
<li>Corrections happen <em>after</em> the mistake is made</li>
<li>Oscillations are reduced but not eliminated</li>
</ul>
<p>This delayed correction is precisely where Nesterov Accelerated Gradient improves upon momentum.</p>
<h1>Nesterov Accelerated Gradient: The Key Idea</h1>
<p>The defining idea behind NAG is simple:</p>
<p><strong>Instead of computing the gradient at the current position, compute it at the expected future position.</strong></p>
<p>That future position is where momentum is about to take the parameters.</p>
<p>In other words:
- Momentum says: “Move, then see where you ended up.”
- NAG says: “Look ahead, then decide how to move.”</p>
<p>This single change introduces anticipation into the optimization process.</p>
<h1>Lookahead Gradients and Error Correction</h1>
<p>In classical momentum, the optimizer realizes it overshot the minimum only <em>after</em> it has already moved too far. The correction comes late.</p>
<p>With NAG:</p>
<ul>
<li>The gradient is evaluated at the lookahead position</li>
<li>If the optimizer is about to overshoot, the gradient already reflects that</li>
<li>The update is adjusted <em>before</em> the overshoot occurs</li>
</ul>
<p>This early correction leads to:</p>
<ul>
<li>Smaller oscillations</li>
<li>Better alignment with the true descent direction</li>
<li>More stable convergence near minima</li>
</ul>
<p>In effect, NAG behaves like a momentum method with built-in braking.</p>
<h1>Geometric Intuition Behind Faster Convergence</h1>
<p>A useful mental model is to imagine rolling a ball down a curved valley.</p>
<ul>
<li>Momentum is like a heavy ball that keeps rolling forward even when the slope changes.</li>
<li>NAG is like a ball whose driver looks ahead and starts turning the wheel early.</li>
</ul>
<p>In narrow valleys:</p>
<ul>
<li>Momentum oscillates side to side</li>
<li>NAG anticipates the turn and follows the valley floor more closely</li>
</ul>
<p>This tighter trajectory explains why NAG converges faster, especially in problems with ill-conditioned Hessians.</p>
<h1>NAG vs Momentum: Side-by-Side Comparison</h1>
<p>Classical Momentum:</p>
<ul>
<li>Reacts to gradients at the current position</li>
<li>Corrects errors after overshooting</li>
<li>Can oscillate near minima</li>
</ul>
<p>Nesterov Accelerated Gradient:</p>
<ul>
<li>Uses gradients from the lookahead position</li>
<li>Corrects errors before they happen</li>
<li>Produces smoother, more stable updates</li>
</ul>
<p>The difference is subtle in equations but significant in optimization behavior.</p>
<h1>When NAG Helps the Most</h1>
<p>NAG tends to outperform classical momentum when:</p>
<ul>
<li>The loss surface has high curvature</li>
<li>The problem is poorly conditioned</li>
<li>Fast convergence is required without excessive tuning</li>
<li>Training deep neural networks with smooth loss landscapes</li>
</ul>
<p>In simple or well-conditioned problems, the difference may be minor, but in deep learning settings it often becomes noticeable.</p>
<h1>Common Misconceptions</h1>
<p>-&gt; <em>“NAG is just momentum with a different formula”</em><br/>
While the equations look similar, the optimization dynamics are fundamentally different due to the lookahead gradient.</p>
<p>-&gt; <em>“NAG is obsolete because Adam exists”</em><br/>
Adaptive optimizers solve a different problem. NAG remains highly relevant, especially in theoretical optimization and large-batch training.</p>
<p>-&gt; <em>“NAG always converges faster”</em><br/>
Like all optimizers, NAG depends on learning rates and problem structure. It is faster in many but not all cases.</p>
<h1>Key Takeaways</h1>
<ol>
<li>Momentum accelerates gradient descent by accumulating past gradients.</li>
<li>Classical momentum reacts too late to changes in the loss surface.</li>
<li>Nesterov Accelerated Gradient computes gradients at a lookahead position.</li>
<li>This anticipation leads to earlier corrections and smoother trajectories.</li>
<li>Faster convergence comes from better geometric alignment, not magic.</li>
</ol>
<h1>Conclusion</h1>
<p>Nesterov Accelerated Gradient improves upon classical momentum by introducing foresight into gradient-based optimization. By evaluating gradients at the anticipated future position, NAG corrects overshooting before it happens, resulting in faster and more stable convergence.</p>
<p>This seemingly small change has profound effects on optimization dynamics, especially in high-dimensional and ill-conditioned problems common in machine learning. Understanding <em>why</em> NAG works provides deeper insight into optimization itself and helps practitioners choose the right tool for efficient training.</p>

                        <div class="mt-16 border-t border-gray-100 pt-10">
                            <h2 class="text-2xl font-bold tracking-tight text-gray-900 mb-6">Suggested Posts</h2>
                            <div class="grid grid-cols-1 gap-6 sm:grid-cols-2 lg:grid-cols-3">
                                
                                <div class="group relative flex flex-col items-start justify-between p-6 bg-white rounded-lg transition-colors duration-200 hover:bg-gray-50 border border-gray-200 hover:border-indigo-300">
                                    <div class="flex items-center gap-x-2 text-[10px] mb-4">
                                        <time datetime="2022-11-11 06:33:09" class="text-gray-400 uppercase tracking-wider">November 11, 2022</time>
                                    </div>
                                    <h3 class="text-lg font-semibold leading-6 text-gray-900">
                                        <a href="/nesterov-accelerated-gradient-nag-optimizer-in-deep-learning">
                                            <span class="absolute inset-0"></span>
                                            Nesterov Accelerated Gradient (NAG) Optimizer in Deep Learning
                                        </a>
                                    </h3>
                                    <p class="mt-4 line-clamp-3 text-sm leading-6 text-gray-500">
                                        In deep learning, optimizers are the type of function which are used to adjust the parameters of the...
                                    </p>
                                    <div class="mt-4 flex items-center text-xs font-semibold text-indigo-600">
                                        Read article
                                        <svg xmlns="http://www.w3.org/2000/svg" class="h-3 w-3 ml-1" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="9 5l7 7-7 7" />
                                        </svg>
                                    </div>
                                </div>
                                
                                <div class="group relative flex flex-col items-start justify-between p-6 bg-white rounded-lg transition-colors duration-200 hover:bg-gray-50 border border-gray-200 hover:border-indigo-300">
                                    <div class="flex items-center gap-x-2 text-[10px] mb-4">
                                        <time datetime="2019-01-24 14:00:21" class="text-gray-400 uppercase tracking-wider">January 24, 2019</time>
                                    </div>
                                    <h3 class="text-lg font-semibold leading-6 text-gray-900">
                                        <a href="/machine-learning-part-4-gradient-descent-and-cost-function">
                                            <span class="absolute inset-0"></span>
                                            Machine Learning Part 4: Gradient Descent and Cost Function
                                        </a>
                                    </h3>
                                    <p class="mt-4 line-clamp-3 text-sm leading-6 text-gray-500">
                                        In this part, we explore the engine under the hood of most machine learning algorithms: Optimization...
                                    </p>
                                    <div class="mt-4 flex items-center text-xs font-semibold text-indigo-600">
                                        Read article
                                        <svg xmlns="http://www.w3.org/2000/svg" class="h-3 w-3 ml-1" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="9 5l7 7-7 7" />
                                        </svg>
                                    </div>
                                </div>
                                
                                <div class="group relative flex flex-col items-start justify-between p-6 bg-white rounded-lg transition-colors duration-200 hover:bg-gray-50 border border-gray-200 hover:border-indigo-300">
                                    <div class="flex items-center gap-x-2 text-[10px] mb-4">
                                        <time datetime="2022-12-13 11:23:46" class="text-gray-400 uppercase tracking-wider">December 13, 2022</time>
                                    </div>
                                    <h3 class="text-lg font-semibold leading-6 text-gray-900">
                                        <a href="/relu-activation-function-and-its-variants">
                                            <span class="absolute inset-0"></span>
                                            ReLU Activation Function and Its Variants
                                        </a>
                                    </h3>
                                    <p class="mt-4 line-clamp-3 text-sm leading-6 text-gray-500">
                                        Activation functions in deep learning are the functions that decide the output from node or hidden l...
                                    </p>
                                    <div class="mt-4 flex items-center text-xs font-semibold text-indigo-600">
                                        Read article
                                        <svg xmlns="http://www.w3.org/2000/svg" class="h-3 w-3 ml-1" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="9 5l7 7-7 7" />
                                        </svg>
                                    </div>
                                </div>
                                
                            </div>
                        </div>

                        <script src="https://utteranc.es/client.js"
        repo="pythonkitchen/blog-comments"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
                    </article>
                
                  </div>
                
            </div>
        </div>
        
    </div>
    <div class="col-span-1">
        <div class="p-8 pl-12">
            <div class="ml-2">
                <div class=" bg-white rounded-lg shadow-lg" style="padding: 5px">
                    <article>
                        <a  target="_blank" href="https://leanpub.com/c/flask-masterclass">
                            <img id="side-img" src="/assets/flaskcoursefree.png" style="width: 100% !important">
                        </a>
                        Free Flask Course
                    </article>
                    </div>
                    
                    
            </div>
        </div>

        
    </div>
  </div>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script>hljs.highlightAll();</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.4/js/lightbox.min.js" integrity="sha512-Ixzuzfxv1EqafeQlTCufWfaC6ful6WFqIz4G+dWvK0beHw0NVJwvCKSgafpy5gwNqKmgUfIBraVwkKI+Cz0SEQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script type="text/javascript">
    var img = jQuery("img");

img.each(function() {
   var element = jQuery(this);
   var a = jQuery("<a />", {href: element.attr("src"), "data-lightbox": "test"});

   element.wrap(a);
});

    $("#side-img").parent().removeAttr( "data-lightbox" ).attr("href","https://leanpub.com/c/flask-masterclass").attr("target","_blank");
</script>

</body>
</html>